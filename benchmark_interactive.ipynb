{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c7ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import cupy \n",
    "import time\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f7715",
   "metadata": {},
   "source": [
    "## NumPy (CPU) vs. CuPy (GPU) -- math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988eea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiplication_helper(m, sh):\n",
    "    m = importlib.import_module(mod)\n",
    "    start = time.time()\n",
    "    a = m.random.random(sh)\n",
    "    a.dot(a)\n",
    "    end = time.time()\n",
    "    return end-start\n",
    "    \n",
    "\n",
    "def sum_helper(m, sh):\n",
    "    m = importlib.import_module(mod)\n",
    "    start = time.time()\n",
    "    a = m.random.random(sh)\n",
    "    a.sum\n",
    "    end = time.time()\n",
    "    return end-start\n",
    "\n",
    "\n",
    "funcs = [matrix_multiplication_helper, sum_helper]\n",
    "modules = ['numpy', 'cupy']\n",
    "shapes = [(1000, 1000), (10000, 10000), (20000, 20000)]\n",
    "duplicates = 3\n",
    "\n",
    "for fun in funcs:\n",
    "    print(f\"\\nFUN : \", fun)\n",
    "    for mod in modules: \n",
    "        print('module : ',mod)\n",
    "        for sh in shapes:\n",
    "            print('shape : ', sh)\n",
    "            dup_sum = 0\n",
    "            for i in range(duplicates):\n",
    "                exec_time = fun(mod,sh)\n",
    "                print('time : ', exec_time)\n",
    "                dup_sum += exec_time\n",
    "                time.sleep(8)\n",
    "            print('avg : ', dup_sum/(1.*duplicates))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235494a",
   "metadata": {},
   "source": [
    "## Pandas (CPU) vs. CuDF (GPU) -- data frame operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88145ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '<PATH_TO_DATA>'\n",
    "file_name1 = 'yellow_tripdata_2015-01.csv'\n",
    "file_name2 = 'yellow_tripdata_2015-02.csv'\n",
    "data_path = data_dir + file_name1\n",
    "data_path2 = [data_dir + file_name1, data_dir + file_name2] \n",
    "\n",
    "def read_csv(mod, data_path, nrows):\n",
    "    m = importlib.import_module(mod)\n",
    "    start = time.time()\n",
    "    df = m.read_csv(data_path, nrows=nrows)\n",
    "    end = time.time()\n",
    "    return end-start\n",
    "\n",
    "def merge_DataFrames(mod, data_path2, nrows):\n",
    "    m = importlib.import_module(mod)\n",
    "    start = time.time()\n",
    "    dfs = [m.read_csv(p, nrows=nrows) for p in data_path2]\n",
    "    merged_df = dfs[0].merge(dfs[1], on=\"trip_distance\")\n",
    "    end = time.time()\n",
    "    return end-start\n",
    "\n",
    "\n",
    "funcs = [read_csv, merge_DataFrames]\n",
    "modules = ['pandas', 'cudf']\n",
    "nrows = 10_000_000\n",
    "duplicates = 4\n",
    "\n",
    "for fun in funcs:\n",
    "    print(f\"\\nFUN : \", fun)\n",
    "    for mod in modules:\n",
    "        print(f\"\\nModule: {mod}\")\n",
    "        dup_sum = 0\n",
    "        for i in range(duplicates):\n",
    "              exec_time = read_csv(mod, data_path, nrows)\n",
    "              print(f\"Run {i+1}: {exec_time:.4f} sec\")\n",
    "              dup_sum += exec_time\n",
    "        print(f\"Avg time: {dup_sum / duplicates:.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2cf0a9",
   "metadata": {},
   "source": [
    "## SkLearn (CPU) vs CuML (GPU) -- Machine Learning Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d439099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numba, numba.cuda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "mortgage_data_path = '<PATH_TO_DATA>'\n",
    "mortgage_file = 'mortgage.npy.gz'\n",
    "\n",
    "\n",
    "\n",
    "def load_data(nrows, ncols, cached, train_split=1.0, label_col=None):\n",
    "    import gzip\n",
    "    import os\n",
    "   \n",
    "    train_rows = int(nrows * train_split)\n",
    "\n",
    "    if os.path.exists(cached):\n",
    "        with gzip.open(cached) as f:\n",
    "            X = np.load(f)\n",
    "\n",
    "        if train_split < 1.0 and label_col is not None:\n",
    "            X = X[:, [i for i in range(X.shape[1]) if i != label_col]]\n",
    "            y = X[:, label_col : label_col + 1]\n",
    "            rindices = np.random.randint(0, X.shape[0] - 1, nrows)\n",
    "            X = X[rindices, :ncols]\n",
    "            y = y[rindices]\n",
    "            df_y_train = pd.DataFrame(\n",
    "                {\"fea%d\" % i: y[0:train_rows, i] for i in range(y.shape[1])}\n",
    "            )\n",
    "            df_y_test = pd.DataFrame(\n",
    "                {\"fea%d\" % i: y[train_rows:, i] for i in range(y.shape[1])}\n",
    "            )\n",
    "        else:\n",
    "            X = X[np.random.randint(0, X.shape[0] - 1, nrows), :ncols]\n",
    "\n",
    "    else:\n",
    "        # throws FileNotFoundError error if mortgage dataset is not present\n",
    "        raise FileNotFoundError(\n",
    "            \"Please download the required dataset or check the path\"\n",
    "        )\n",
    "\n",
    "    if train_split < 1.0 and label_col is not None:\n",
    "        df_X_train = pd.DataFrame(\n",
    "            {\"fea%d\" % i: X[0:train_rows, i] for i in range(X.shape[1])}\n",
    "        )\n",
    "        df_X_test = pd.DataFrame(\n",
    "            {\"fea%d\" % i: X[train_rows:, i] for i in range(X.shape[1])}\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"X_train\": df_X_train,\n",
    "            \"X_test\": df_X_test,\n",
    "            \"y_train\": df_y_train,\n",
    "            \"y_test\": df_y_test,\n",
    "        }\n",
    "    else:\n",
    "        df = pd.DataFrame({\"fea%d\" % i: X[:, i] for i in range(X.shape[1])})\n",
    "        return df\n",
    "\n",
    "\n",
    "def load_mortgage(mod, shape, data_path):\n",
    "    data = load_data(nrows=shape[0], ncols=shape[1], cached=data_path, train_split=0.8, label_col=4)\n",
    "    \n",
    "    if mod == \"cuml\":\n",
    "        import cudf\n",
    "        if isinstance(data, dict):\n",
    "            for k, v in data.items():\n",
    "                data[k] = cudf.DataFrame.from_pandas(v)\n",
    "            data[\"y_train\"] = cudf.Series(data[\"y_train\"][\"fea0\"])\n",
    "        else:\n",
    "            data = cudf.DataFrame.from_pandas(data)\n",
    "    \n",
    "    return {\"module\": mod, \"data\": data}\n",
    "    \n",
    "\n",
    "def run_benchmark(mod, shape, data_path, duplicates):\n",
    "    for helper_func in [linear_regression]:\n",
    "        print(f\"\\n{helper_func.__name__.replace('_helper', '').replace('_', ' ').title()} - Module: {mod}, Shape: {shape}\")\n",
    "        dup_sum = 0\n",
    "        for i in range(duplicates):\n",
    "            exec_time = helper_func(mod, shape, data_path)\n",
    "            print(f\"Run {i+1}: {exec_time:.4f} sec\")\n",
    "            dup_sum += exec_time\n",
    "        print(f\"Avg time: {dup_sum / duplicates:.4f} sec\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def linear_regression(mod, shape, data_path):\n",
    "    if mod == \"sklearn\":\n",
    "        m = importlib.import_module(\"sklearn.linear_model\")\n",
    "    else:\n",
    "        m = importlib.import_module(\"cuml\")\n",
    "    \n",
    "    data = load_mortgage(mod, shape, data_path)\n",
    "    X_train = data[\"data\"][\"X_train\"]\n",
    "    y_train = data[\"data\"][\"y_train\"]\n",
    "    \n",
    "    kwargs = {\"fit_intercept\": True}\n",
    "    if mod == \"cuml\":\n",
    "        kwargs[\"algorithm\"] = \"eig\"\n",
    "    \n",
    "    lr = m.LinearRegression(**kwargs)\n",
    "    \n",
    "    start = time.time()\n",
    "    lr.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    return end - start\n",
    "   \n",
    "    \n",
    "    \n",
    "\n",
    "modules = [\"sklearn\", \"cuml\"]\n",
    "shapes = [(int(2 ** 20), 512), (int(2 ** 21), 512), (int(2 ** 22), 512)]\n",
    "data_path = mortgage_data_path + mortgage_file\n",
    "duplicates = 4\n",
    "\n",
    "for mod in modules:\n",
    "    for shape in shapes:\n",
    "        run_benchmark(mod, shape, data_path, duplicates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d8dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12 (p312_cupy_gpu)",
   "language": "python",
   "name": "py312_cupy_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
